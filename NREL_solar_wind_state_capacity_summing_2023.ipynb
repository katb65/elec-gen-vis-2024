{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f557c60d-c453-49d0-9656-8eca3ecfbffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# where to find the files - in this case, the same directory as this file\n",
    "root_dir = \"\"\n",
    "\n",
    "# ------------------------------\n",
    "\n",
    "# 2023 REPORT DATA\n",
    "\n",
    "# NOTE: this will differ from the NREL vis capacity output (reference), appears to be due to\n",
    "# their not multiplying by cf in order to accurately display how many energy production\n",
    "# mechanisms need buying rather than how much will be produced\n",
    "\n",
    "# will crunch the NREL files to sum the capacity for each state for each file type\n",
    "# factoring in capacity factor; as well as rename Rhode Island & convert MW -> GWh\n",
    "\n",
    "# file names\n",
    "solar_open_big_name = \"solar_open_capacity_2023_NREL.csv\"\n",
    "solar_reference_big_name = \"solar_reference_capacity_2023_NREL.csv\"\n",
    "solar_limited_big_name = \"solar_limited_capacity_2023_NREL.csv\"\n",
    "wind_open_big_name = \"wind_open_capacity_2023_NREL.csv\"\n",
    "wind_reference_big_name = \"wind_reference_capacity_2023_NREL.csv\"\n",
    "wind_limited_big_name = \"wind_limited_capacity_2023_NREL.csv\"\n",
    "\n",
    "solar_open_condensed_name = \"solar_open_capacity_2023_NREL_condensed.csv\"\n",
    "solar_reference_condensed_name = \"solar_reference_capacity_2023_NREL_condensed.csv\"\n",
    "solar_limited_condensed_name = \"solar_limited_capacity_2023_NREL_condensed.csv\"\n",
    "wind_open_condensed_name = \"wind_open_capacity_2023_NREL_condensed.csv\"\n",
    "wind_reference_condensed_name = \"wind_reference_capacity_2023_NREL_condensed.csv\"\n",
    "wind_limited_condensed_name = \"wind_limited_capacity_2023_NREL_condensed.csv\"\n",
    "\n",
    "# read CSVs\n",
    "solar_open_big = pd.read_csv(root_dir + solar_open_big_name)\n",
    "solar_reference_big = pd.read_csv(root_dir + solar_reference_big_name)\n",
    "solar_limited_big = pd.read_csv(root_dir + solar_limited_big_name)\n",
    "wind_open_big = pd.read_csv(root_dir + wind_open_big_name)\n",
    "wind_reference_big = pd.read_csv(root_dir + wind_reference_big_name)\n",
    "wind_limited_big = pd.read_csv(root_dir + wind_limited_big_name)\n",
    "\n",
    "big_arr = [solar_open_big, solar_reference_big, solar_limited_big,\n",
    "          wind_open_big, wind_reference_big, wind_limited_big]\n",
    "\n",
    "# visually verify CSVs (column headers & amount of columns)\n",
    "print(\"Big:\")\n",
    "for b in big_arr:\n",
    "    display(b)\n",
    "\n",
    "# make dictionaries (to later convert to DataFrames, then to Excel files)\n",
    "# to compile state sums\n",
    "solar_open_condensed_d = dict()\n",
    "solar_reference_condensed_d = dict()\n",
    "solar_limited_condensed_d = dict()\n",
    "wind_open_condensed_d = dict()\n",
    "wind_reference_condensed_d = dict()\n",
    "wind_limited_condensed_d = dict()\n",
    "\n",
    "# same order as big_arr\n",
    "condensed_d_arr = [solar_open_condensed_d, solar_reference_condensed_d, solar_limited_condensed_d,\n",
    "                wind_open_condensed_d, wind_reference_condensed_d, wind_limited_condensed_d]\n",
    "\n",
    "# loop over files to condense\n",
    "for i in range(0,6):\n",
    "    # loop over columns in big file\n",
    "    curr_big = big_arr[i]\n",
    "    curr_condensed_d = condensed_d_arr[i]\n",
    "    curr_rows = curr_big.shape[0]\n",
    "    # visually verify curr_rows\n",
    "    print(curr_rows)\n",
    "    \n",
    "    for j in range(0, curr_rows):\n",
    "        curr_state = curr_big.at[j, 'state']\n",
    "        if(curr_state == \"Rhode Island and Providence Plantations\"): # rename Rhode Island to match with our JS code\n",
    "            curr_state = \"Rhode Island\"\n",
    "        \n",
    "        curr_capacity = None\n",
    "        if(i <= 2): # solar\n",
    "            curr_capacity = curr_big.at[j, 'capacity_mw_ac'] * curr_big.at[j, 'mean_cf_ac']\n",
    "        else: # wind\n",
    "            curr_capacity = curr_big.at[j, 'capacity_mw'] * curr_big.at[j, 'mean_cf']\n",
    "        \n",
    "        # add this capacity to the condensed output\n",
    "        if curr_state in curr_condensed_d:\n",
    "            curr_condensed_d[curr_state] = curr_condensed_d[curr_state] + curr_capacity\n",
    "        else:\n",
    "            curr_condensed_d[curr_state] = curr_capacity\n",
    "            \n",
    "# visually verify condensed dictionaries + print lengths\n",
    "print(\"Condensed:\")\n",
    "for cd in condensed_d_arr:\n",
    "    display(cd)\n",
    "    print(str(len(cd)) + \" rows\")\n",
    "    \n",
    "# reformat dictionaries to prep to be made into dataframes for export\n",
    "solar_open_condensed_prep = []\n",
    "solar_reference_condensed_prep = []\n",
    "solar_limited_condensed_prep = []\n",
    "wind_open_condensed_prep = []\n",
    "wind_reference_condensed_prep = []\n",
    "wind_limited_condensed_prep = []\n",
    "\n",
    "condensed_prep_arr = [solar_open_condensed_prep, solar_reference_condensed_prep, solar_limited_condensed_prep,\n",
    "                     wind_open_condensed_prep, wind_reference_condensed_prep, wind_limited_condensed_prep]\n",
    "for i in range(0, 6):\n",
    "    curr_condensed_d = condensed_d_arr[i]\n",
    "    curr_condensed_prep = condensed_prep_arr[i]\n",
    "    \n",
    "    for k in curr_condensed_d.keys():\n",
    "        curr_to_gwh = curr_condensed_d[k] * 0.001 * 365 * 24 # convert to GWh for consistency with JS file\n",
    "        curr_two = [k, curr_to_gwh]\n",
    "        curr_condensed_prep.append(curr_two)\n",
    "\n",
    "# visually verify condensed prep arrays\n",
    "print(\"Condensed prep:\")\n",
    "for cpr in condensed_prep_arr:\n",
    "    display(cpr)\n",
    "    \n",
    "# convert arrays to dataframes\n",
    "solar_open_condensed_df = pd.DataFrame(solar_open_condensed_prep, columns=[\"state\", \"capacity_gwh\"])\n",
    "solar_reference_condensed_df = pd.DataFrame(solar_reference_condensed_prep, columns=[\"state\", \"capacity_gwh\"])\n",
    "solar_limited_condensed_df = pd.DataFrame(solar_limited_condensed_prep, columns=[\"state\", \"capacity_gwh\"])\n",
    "wind_open_condensed_df = pd.DataFrame(wind_open_condensed_prep, columns=[\"state\", \"capacity_gwh\"])\n",
    "wind_reference_condensed_df = pd.DataFrame(wind_reference_condensed_prep, columns=[\"state\", \"capacity_gwh\"])\n",
    "wind_limited_condensed_df = pd.DataFrame(wind_limited_condensed_prep, columns=[\"state\", \"capacity_gwh\"])\n",
    "\n",
    "# convert dataframes to exported csv files into our root dir (uncomment to modify local files aka export)\n",
    "#solar_open_condensed_df.to_csv(root_dir + solar_open_condensed_name, header=True)\n",
    "#solar_reference_condensed_df.to_csv(root_dir + solar_reference_condensed_name, header=True)\n",
    "#solar_limited_condensed_df.to_csv(root_dir + solar_limited_condensed_name, header=True)\n",
    "#wind_open_condensed_df.to_csv(root_dir + wind_open_condensed_name, header=True)\n",
    "#wind_reference_condensed_df.to_csv(root_dir + wind_reference_condensed_name, header=True)\n",
    "#wind_limited_condensed_df.to_csv(root_dir + wind_limited_condensed_name, header=True)\n",
    "\n",
    "# check files in your dir & verify values and row count against the printed ones\n",
    "print(\"Done! Not printed to file (commented out)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792d0cc6-fdcf-42ed-b0c7-c12249f3a464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# 2021 OFFSHORE WIND DATA\n",
    "# (is not split by state in file)\n",
    "\n",
    "# WHOLE SUM\n",
    "# summing just the offshore wind files; not currently in the stock of those loaded & displayed in the vis\n",
    "offshore_wind_open_big_name = \"offshore_wind_open_capacity_2021_NREL.csv\"\n",
    "offshore_wind_limited_big_name = \"offshore_wind_limited_capacity_2021_NREL.csv\"\n",
    "\n",
    "offshore_wind_condensed_name = \"offshore_wind_capacity_2021_NREL_condensed.csv\" # it'll be 2 numbers, both go into 1 file\n",
    "\n",
    "offshore_wind_open_big = pd.read_csv(root_dir + offshore_wind_open_big_name);\n",
    "offshore_wind_limited_big = pd.read_csv(root_dir + offshore_wind_limited_big_name);\n",
    "\n",
    "# vis verify\n",
    "display(offshore_wind_open_big)\n",
    "display(offshore_wind_limited_big)\n",
    "\n",
    "# going to take into account capacity factor of each row & conversion\n",
    "offshore_wind_open_sum_gwh = 0;\n",
    "offshore_wind_limited_sum_gwh = 0;\n",
    "\n",
    "owo_rows = offshore_wind_open_big.shape[0]\n",
    "owl_rows = offshore_wind_limited_big.shape[0]\n",
    "\n",
    "# vis verify\n",
    "print(str(owo_rows) + \" rows in open\")\n",
    "print(str(owl_rows) + \" rows in limited\")\n",
    "\n",
    "for r in range(0, owo_rows):\n",
    "    curr_capacity = offshore_wind_open_big.at[r, \"capacity_mw\"]\n",
    "    curr_cf = offshore_wind_open_big.at[r, \"capacity_factor\"]\n",
    "    \n",
    "    curr_val = curr_capacity * curr_cf * 0.001 * 365 * 24 # to GWh\n",
    "    \n",
    "    offshore_wind_open_sum_gwh += curr_val;\n",
    "    \n",
    "for r in range(0, owl_rows):\n",
    "    curr_capacity = offshore_wind_limited_big.at[r, \"capacity_mw\"]\n",
    "    curr_cf = offshore_wind_limited_big.at[r, \"capacity_factor\"]\n",
    "    \n",
    "    curr_val = curr_capacity * curr_cf * 0.001 * 365 * 24 # to GWh\n",
    "    \n",
    "    offshore_wind_limited_sum_gwh += curr_val;\n",
    "    \n",
    "# vis verify\n",
    "print(\"2021 US offshore wind open capacity: \" + str(offshore_wind_open_sum_gwh) + \" GWh\")\n",
    "print(\"2021 US offshore wind limited capacity: \" + str(offshore_wind_limited_sum_gwh) + \" GWh\")\n",
    "\n",
    "offshore_wind_condensed_prep = []\n",
    "offshore_wind_condensed_prep.append([\"open\", offshore_wind_open_sum_gwh])\n",
    "offshore_wind_condensed_prep.append([\"limited\", offshore_wind_limited_sum_gwh])\n",
    "\n",
    "# vis verify\n",
    "display(offshore_wind_condensed_prep)\n",
    "\n",
    "# convert to df & export (uncomment to modify local files aka export)\n",
    "offshore_wind_condensed_df = pd.DataFrame(offshore_wind_condensed_prep, columns=[\"type\", \"capacity_gwh_us\"])\n",
    "#offshore_wind_condensed_df.to_csv(root_dir + offshore_wind_condensed_name, header=True)\n",
    "\n",
    "print(\"Done! Not printed to file (commented out)\")\n",
    "\n",
    "# ------------------------------\n",
    "\n",
    "# TEST: SPLITTING LONGITUDES\n",
    "split_at_long = -100; # atlantic + gulf vs pacific\n",
    "split_gulf_at_long = -81.5; # gulf of mexico vs atlantic\n",
    "\n",
    "offshore_wind_open_atlantic_sum_gwh = 0;\n",
    "offshore_wind_open_pacific_sum_gwh = 0;\n",
    "offshore_wind_open_gulf_sum_gwh = 0;\n",
    "\n",
    "offshore_wind_limited_atlantic_sum_gwh = 0;\n",
    "offshore_wind_limited_pacific_sum_gwh = 0;\n",
    "offshore_wind_limited_gulf_sum_gwh = 0;\n",
    "\n",
    "for r in range(0, owo_rows):\n",
    "    curr_capacity = offshore_wind_open_big.at[r, \"capacity_mw\"]\n",
    "    curr_cf = offshore_wind_open_big.at[r, \"capacity_factor\"]\n",
    "    curr_long = offshore_wind_open_big.at[r, \"longitude\"]\n",
    "    \n",
    "    curr_val = curr_capacity * curr_cf * 0.001 * 365 * 24 # to GWh\n",
    "    \n",
    "    if(curr_long > split_gulf_at_long):\n",
    "        offshore_wind_open_atlantic_sum_gwh += curr_val;\n",
    "    elif(curr_long > split_at_long):\n",
    "        offshore_wind_open_gulf_sum_gwh += curr_val;\n",
    "    else:\n",
    "        offshore_wind_open_pacific_sum_gwh += curr_val;\n",
    "        \n",
    "for r in range(0, owl_rows):\n",
    "    curr_capacity = offshore_wind_limited_big.at[r, \"capacity_mw\"]\n",
    "    curr_cf = offshore_wind_limited_big.at[r, \"capacity_factor\"]\n",
    "    curr_long = offshore_wind_limited_big.at[r, \"longitude\"]\n",
    "    \n",
    "    curr_val = curr_capacity * curr_cf * 0.001 * 365 * 24 # to GWh\n",
    "    \n",
    "    if(curr_long > split_gulf_at_long):\n",
    "        offshore_wind_limited_atlantic_sum_gwh += curr_val;\n",
    "    elif(curr_long > split_at_long):\n",
    "        offshore_wind_limited_gulf_sum_gwh += curr_val;\n",
    "    else:\n",
    "        offshore_wind_limited_pacific_sum_gwh += curr_val;\n",
    "\n",
    "print(\"\")\n",
    "print(\"TEST: offshore wind open atlantic sum: \" + str(offshore_wind_open_atlantic_sum_gwh) + \" GWh\")\n",
    "print(\"TEST: offshore wind open gulf sum: \" + str(offshore_wind_open_gulf_sum_gwh) + \" GWh\")\n",
    "print(\"TEST: offshore wind open pacific sum: \" + str(offshore_wind_open_pacific_sum_gwh) + \" GWh\")\n",
    "print(\"\")\n",
    "print(\"TEST: offshore wind limited atlantic sum: \" + str(offshore_wind_limited_atlantic_sum_gwh) + \" GWh\")\n",
    "print(\"TEST: offshore wind limited gulf sum: \" + str(offshore_wind_limited_gulf_sum_gwh) + \" GWh\")\n",
    "print(\"TEST: offshore wind limited pacific sum: \" + str(offshore_wind_limited_pacific_sum_gwh) + \" GWh\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24593db7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
